/**
 * # Parameters for nf-maccoss-trex
 *
 * A NextFlow pipeline for analyzing data-ind
 */
params {
    /** \group{Input/Output Parameters} */

    /** \type{string} \required
     *  Path to the FASTA file containing the subset of proteins sequences to
     *  search.
     */
    fasta = null

    /** \type{string} \required
     *  The mzML file containing the spectra to search
     */
    mzml = null

    result_dir = 'results' /** \type{str} Where results will be saved. */
    report_dir = 'reports' /** \type{str} Where results will be saved. */
    email = null           /** \type{str} An email to alert on completion. */

    /** \group{Resources}
     *  Change these to reflect your compute environment.
     */
    max_memory = '8.GB' /** \type{string} The maximum memory allowed for each process. */
    max_cpus = 16         /** \type{integer} The maximum number of CPUs for each process. */
    max_time = '240.h'    /** \type{string} The maximum executrion time for each process. */

    limelight_xml_conversion_params = '-Xmx32192m '
}

// Containers
process {
    withName:COMET_ONCE {
        container = 'mriffle/comet:2022012'
    }
    withName:PERCOLATOR {
        container = 'mriffle/percolator:3.05'
    }
    withName:CONVERT_TO_LIMELIGHT_XML {
        container = 'mriffle/comet-percolator-to-limelight:2.6.4'
    }    
}
docker {
    enabled = true
}

// Manifest
manifest {
    name            = 'nf-teirex-dda'
    author          = 'Michael Riffle'
    homePage        = 'https://github.com/mriffle/nf-teirex-dda'
    description     = 'DDA workflows for TEI-REX project'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=21.10.3'
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']
def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.report_dir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.report_dir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.report_dir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.report_dir}/pipeline_dag_${trace_timestamp}.html"
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit. Copied from the nf-core template.
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
