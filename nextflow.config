/**
 * # Parameters for nf-maccoss-trex
 *
 * A NextFlow pipeline for analyzing data-ind
 */
params {
    /** \group{Input/Output Parameters} */

    /** \type{string} \required
     *  Path to the FASTA file containing the subset of proteins sequences to
     *  search.
     */
    fasta = null

    /** \type{string} \required
     *  The directory containing the mzML or raw files to search
     */
    spectra_dir = null

    /** \type{string} \required
     *  Location of the comet params file
     */
    comet_params = 'comet.params'

    /** \type{boolean} \required
     *  Whether to post-process all comet results separately. If true, each comet result file will
     *  be processed separately by Percolator and, if requested, uploaded to Limelight as a
     *  separate search. If false, all comet results are combined together for a single Percolator
     *  run, and the combined result will be uploaded to Limelight as a single search with
     *  sub searches.
     */
    process_separately = false
    
    result_dir = 'results/nf-ms-dda-comet' /** \type{str} Where results will be saved. */
    report_dir = 'reports/nf-ms-dda-comet' /** \type{str} Where results will be saved. */
    email = null           /** \type{str} An email to alert on completion. */

    // Limelight params
    limelight_tags = null
    limelight_upload = false
    limelight_import_decoys = false
    limelight_entrapment_prefix = null
}

plugins {
    id 'nf-amazon'
}

docker {
    enabled = true
}

/*
 * Set up secrets in the environment. 
 * Need to do it this way because Nextflow doesn't allow the use of secrets when running on AWS Batch
 */
secret_value = env.LIMELIGHT_SUBMIT_UPLOAD_KEY = nextflow.secret.SecretsLoader.instance.load().getSecret("LIMELIGHT_SUBMIT_UPLOAD_KEY")
if(secret_value) {
    env.LIMELIGHT_SUBMIT_UPLOAD_KEY = secret_value.value
}

secret_value = nextflow.secret.SecretsLoader.instance.load().getSecret("PANORAMA_API_KEY")
if(secret_value) {
    env.PANORAMA_API_KEY = secret_value.value
}

// Execution Profiles
profiles {

    /*
     * Params for running pipeline on the local computer (e.g.:
     * your laptop). These can be overridden in the local config file.
     */
    standard {
        process.executor = 'local'

        // limit nextflow to running 1 task at a time
        executor.queueSize = 1

        params.max_memory = '12.GB'
        params.max_cpus = 8
        params.max_time = '240.h'

        // where to cache mzml files after running msconvert
        params.mzml_cache_directory = '/data/mass_spec/nextflow/nf-teirex-dda/mzml_cache'
        params.panorama_cache_directory = '/data/mass_spec/nextflow/panorama/raw_cache'
    }

    slurm {
        process.executor = 'slurm'

        params.max_memory = '12.GB'
        params.max_cpus = 8
        params.max_time = '240.h'

        // where to cache mzml files after running msconvert
        params.mzml_cache_directory = '/data/mass_spec/nextflow/nf-teirex-dda/mzml_cache'
        params.panorama_cache_directory = '/data/mass_spec/nextflow/panorama/raw_cache'
    }

}

// Manifest
manifest {
    name            = 'nf-teirex-dda'
    author          = 'Michael Riffle'
    homePage        = 'https://github.com/mriffle/nf-teirex-dda'
    description     = 'Automated Nextflow workflow for processing data with comet, percolator and uploading to Limelight.'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=21.10.3'
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']
def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.report_dir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.report_dir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.report_dir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = false
    file    = "${params.report_dir}/pipeline_dag_${trace_timestamp}.html"
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load the images to use for all processes
includeConfig 'container_images.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit. Copied from the nf-core template.
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
